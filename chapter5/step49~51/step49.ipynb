{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ff4fd51-08e8-4244-88eb-ba5cc72f203d",
   "metadata": {},
   "source": [
    "# STEP49 Datasetクラスと前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c42517f",
   "metadata": {},
   "source": [
    "## このSTEPの概要\n",
    "\n",
    "### STEP48で学んだこととその課題\n",
    "\n",
    "- スパイラルデータセットを使って多値分類をおこなった。\n",
    "    - `x, t = dezero.datasets.get_spiral()` というコードでテータの読み込みを行った\n",
    "        - `x`: (300, 2), ndarray\n",
    "        - `t`: (300,), ndarray\n",
    "- しかしHWが保持しているメモリより大規模なデータセットを扱う場合、すべてのデータをこのようにndarrayに読むことができない課題がある\n",
    "- また前処理に関して標準化された仕様になっていない。\n",
    "\n",
    "### STEP49の目的\n",
    "\n",
    "上記のような問題に対応できるようにデータセット専用のクラス `Dataset` クラスを作る。更に前処理を行える仕組みも入れる\n",
    "\n",
    "- 49.1 Datasetクラスの実装\n",
    "    - `dezero/datasets.py` に`Dataset` クラスを実装\n",
    "    - `dezero/datasets.py` に`Spiral`クラスを実装\n",
    "- 49.2 大きいデータセットの場合\n",
    "    - `dezero/datasets.py` に `BigData` クラスを実装\n",
    "- 49.3 データの連結\n",
    "    - インデックス操作によりミニバッチに対応する複数データを取り出す\n",
    "        - [3, 5, 8, 2, 1] => Indexがシャフルされ、その値が抽出される。。。。\n",
    "- 49.4 学習用のコード\n",
    "    - DatasetクラスによりSpiralデータセットのコードがSTEP48と比較してどう変わるか確認する\n",
    "- 49.5 データセットの前処理\n",
    "    - 前処理およびデータ拡張を対応可能にするために、ユーザが定義した関数を関数オブジェクトで引数で渡せるようにする\n",
    "\n",
    "### Datasetクラスで必要な仕様は以下の２つである\n",
    "\n",
    "いったん以下を頭に入れておけば良い\n",
    "\n",
    "- Dataset クラスで必要な条件は以下の２つのメソッドを含んでいること\n",
    "    - `__getitem__`: Pythonの特殊メソッドx[0], x[1]などカッコつきでアクセスしたときの定義\n",
    "    - `__len__`: 例えばlen(x)を使ったときに呼ばれる特殊メソッド"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91764a4e-abd4-476b-8f52-05918573edaa",
   "metadata": {},
   "source": [
    "これまで何をやったか、まとめています。目次より、少し詳しい情報となっています。\n",
    "\n",
    "https://qiita.com/daikumatan/private/1c4ba888ed1928c55fb2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c24913-968e-4254-9b4e-94849f89025e",
   "metadata": {},
   "source": [
    "## 事前準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "976650b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if '__file__' in globals():\n",
    "    import os, sys\n",
    "    sys.path.append(os.path.join(os.path.dirname(__file__), '..'))\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import dezero\n",
    "from dezero import optimizers\n",
    "import dezero.functions as F\n",
    "from dezero.models import MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba226769-c423-4604-9c7a-75af57733b98",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 49.1 Datasetクラスの実装\n",
    "\n",
    "49.1では前述のHWのメモリ量を超えるような、大きいデータはまだ扱えないことに注意する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3283ba2c",
   "metadata": {},
   "source": [
    "### `dezero/datasets.py` に`Dataset` クラスを実装する\n",
    "\n",
    "- コンストラクタ\n",
    "    - 引数 `train`: 学習用とテスト用を区別するためのフラグ\n",
    "    - インスタンス変数 `data`: 入力データを保持する\n",
    "    - インスタンス変数 `label`: ラベルデータを保持する\n",
    "- `__getitem__` メソッド\n",
    "    - pythonの特殊メソッドであり `x[0]`, `x[1]` など、角括弧[]でアクセスしたときの挙動を定義する\n",
    "    - 単に、Datasetクラスの指定されたインデックスのデータを取りだす\n",
    "    - `self.data[index]` で指定されたとき、ラベルにデータが無いときは、`None` を返却する\n",
    "    - スライス機能 (例えば `x[1:3]`) には対応しない\n",
    "- `__len__` メソッド\n",
    "    - `len()`関数を使ったときに呼ばれる"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0a4825",
   "metadata": {},
   "source": [
    "```python\n",
    "class Dataset:\n",
    "    def __init__(self, train=True):\n",
    "        self.train = train\n",
    "        self.data = None     # 教師データ\n",
    "        self.label = None    # ラベルデータ\n",
    "        self.prepare()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        assert np.isscalar(index)  # スカラのみ対応\n",
    "        if self.label is None:\n",
    "            return self.data[index], None\n",
    "        else:\n",
    "            return self.data[index], self.label[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def prepare(self): # 継承先で具体的動作を規定\n",
    "        pass\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35fdc3f4",
   "metadata": {},
   "source": [
    "### `dezero/datasets.py` に`Spiral`クラスを実装する\n",
    "\n",
    "- `Dataset` クラスを継承し、`prepare` メソッドをオーバーライドして実装する\n",
    "    - `get_spriral`は以前実装し説明したため省略"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0897efb",
   "metadata": {},
   "source": [
    "```python\n",
    "class Spiral(Dataset):\n",
    "    def prepare(self):\n",
    "        self.data, self.label = get_spiral(self.train)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc14905",
   "metadata": {},
   "source": [
    "### Spiralクラスのデータ取り出し例\n",
    "\n",
    "- index:0のDataとラベルがタプルとして返却されている"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "b7b2f1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([-0.13981389, -0.00721657], dtype=float32), 1)\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "train_set = dezero.datasets.Spiral(train=True)\n",
    "print(train_set[0])\n",
    "print(len(train_set))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d180210",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 49.2 大きいデータセットの場合"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce473ad1",
   "metadata": {},
   "source": [
    "### `BigData()`クラスの実装例\n",
    "\n",
    "ここでは以下のディレクトリがあることを想定\n",
    "\n",
    "- data/ (100万個のデータが保存)\n",
    "- labe/ (100万個のラベルが保存)\n",
    "\n",
    "データが大きいときは`Dataset`クラスのインスタンス変数 `data`, `label` に直接ndarrayインスタンスを保持できない。  \n",
    "そのためBigDataクラスの初期化時には、それらのデータは読み込まず、データへのアクセスがあったタイミングで読み込むようにする。\n",
    "\n",
    "具体的には以下のステップを踏む\n",
    "\n",
    "- `__getitem__(index)` が呼ばれるタイミングで、dataディレクトリーにあるデータを読み込む\n",
    "- `np.load` に関してはSTEP53で説明"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0d081e",
   "metadata": {},
   "source": [
    "```python\n",
    "class BigData(Dataset):\n",
    "    def __getitem__(self, index):\n",
    "        # indexで指定されたファイルを読み込んでいる。\n",
    "        # このファイルは100万個のデータがそれぞれ保存されている\n",
    "        # つまりイメージとしては100万個セットで1つファイルが複数あり、それをIndexで指定するイメージ\n",
    "        x = np.load('data/{}.npy'.format(index))\n",
    "        t = np.load('label/{}.npy'.format(index))\n",
    "        return x, t\n",
    "    \n",
    "    def __len__():\n",
    "        return 1000000\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e3f83f",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 49.3 データの連結"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953ae38b",
   "metadata": {},
   "source": [
    "### ミニバッチとして取り出すコード\n",
    "\n",
    "- インデックス操作により、ミニバッチに対応する複数データを取り出す\n",
    "- 下記のようなデータとラベルが1セットのデータが取り出せていることを確認できる\n",
    "    - `[(array([-0.13981389, -0.00721657], dtype=float32), 1), ...]`\n",
    "    - ここで、\n",
    "        - `[-0.13981389, -0.00721657]`: Trainデータであり スパイラルデータセットの(x, y)座標\n",
    "        - `1`: ラベルデータ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "454228ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([-0.13981389, -0.00721657], dtype=float32), 1),\n",
       " (array([0.37049392, 0.5820947 ], dtype=float32), 1),\n",
       " (array([ 0.1374263 , -0.17179643], dtype=float32), 2)]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set = dezero.datasets.Spiral()\n",
    "batch_index = [0, 1, 2]\n",
    "batch = [train_set[i] for i in batch_index]\n",
    "batch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e6eccb",
   "metadata": {},
   "source": [
    "### Dezeroの入力データとして利用するために、取り出したデータを`ndarray`インスタンスに変換する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4d37cd36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.13981389 -0.00721657]\n",
      " [ 0.37049392  0.5820947 ]\n",
      " [ 0.1374263  -0.17179643]] (3, 2)\n",
      "[1 1 2] (3,)\n"
     ]
    }
   ],
   "source": [
    "x = np.array([example[0] for example in batch])\n",
    "t = np.array([example[1] for example in batch])\n",
    "\n",
    "print(x, x.shape)\n",
    "print(t, t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69dec241",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 49.4 学習用のコード"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1220c0b",
   "metadata": {},
   "source": [
    "### STEP48からの変更点\n",
    "\n",
    "- Spiralクラスを使うようにした。\n",
    "- それに伴い、ミニバッチを形成するコードを以下のように変更した\n",
    "\n",
    "#### 変更前(STEP48)\n",
    "\n",
    "```python\n",
    "        :\n",
    "x, t = dezero.datasets.get_spiral(train=True)\n",
    "        :\n",
    "    for i in range(max_iter):\n",
    "        batch_index = index[i * batch_size:(i + 1) * batch_size]\n",
    "        batch_x = x[batch_index]\n",
    "        batch_t = t[batch_index]\n",
    "```\n",
    "\n",
    "#### 変更後(STEP4９)\n",
    "\n",
    "```python\n",
    "        :\n",
    "train_set = dezero.datasets.Spiral(train=True)\n",
    "        :\n",
    "    for i in range(max_iter):\n",
    "        batch_index = index[i * batch_size:(i + 1) * batch_size]\n",
    "        batch_x = np.array([example[0] for example in batch])  # data\n",
    "        batch_t = np.array([example[1] for example in batch])  # label\n",
    "```\n",
    "\n",
    "### 変更によるご利益\n",
    "\n",
    "- もし、データサイズが大きくなれば、SpiralクラスをBigdataクラスに変更すれば良い。\n",
    "- つまり簡単にデータセットの入れ替えができるようになった"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ec828867",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 1.00\n",
      "epoch 2, loss 0.94\n",
      "epoch 3, loss 0.88\n",
      "epoch 4, loss 0.84\n",
      "epoch 5, loss 0.85\n",
      "epoch 6, loss 0.82\n",
      "epoch 7, loss 0.80\n",
      "epoch 8, loss 0.78\n",
      "epoch 9, loss 0.76\n",
      "epoch 10, loss 0.80\n",
      "epoch 11, loss 0.78\n",
      "epoch 12, loss 0.78\n",
      "epoch 13, loss 0.78\n",
      "epoch 14, loss 0.78\n",
      "epoch 15, loss 0.76\n",
      "epoch 16, loss 0.77\n",
      "epoch 17, loss 0.76\n",
      "epoch 18, loss 0.78\n",
      "epoch 19, loss 0.75\n",
      "epoch 20, loss 0.75\n",
      "epoch 21, loss 0.77\n",
      "epoch 22, loss 0.76\n",
      "epoch 23, loss 0.75\n",
      "epoch 24, loss 0.75\n",
      "epoch 25, loss 0.75\n",
      "epoch 26, loss 0.76\n",
      "epoch 27, loss 0.74\n",
      "epoch 28, loss 0.74\n",
      "epoch 29, loss 0.72\n",
      "epoch 30, loss 0.75\n",
      "epoch 31, loss 0.75\n",
      "epoch 32, loss 0.74\n",
      "epoch 33, loss 0.72\n",
      "epoch 34, loss 0.72\n",
      "epoch 35, loss 0.74\n",
      "epoch 36, loss 0.71\n",
      "epoch 37, loss 0.71\n",
      "epoch 38, loss 0.73\n",
      "epoch 39, loss 0.70\n",
      "epoch 40, loss 0.73\n",
      "epoch 41, loss 0.70\n",
      "epoch 42, loss 0.69\n",
      "epoch 43, loss 0.70\n",
      "epoch 44, loss 0.69\n",
      "epoch 45, loss 0.72\n",
      "epoch 46, loss 0.71\n",
      "epoch 47, loss 0.69\n",
      "epoch 48, loss 0.67\n",
      "epoch 49, loss 0.67\n",
      "epoch 50, loss 0.67\n",
      "epoch 51, loss 0.66\n",
      "epoch 52, loss 0.66\n",
      "epoch 53, loss 0.64\n",
      "epoch 54, loss 0.64\n",
      "epoch 55, loss 0.63\n",
      "epoch 56, loss 0.62\n",
      "epoch 57, loss 0.61\n",
      "epoch 58, loss 0.60\n",
      "epoch 59, loss 0.60\n",
      "epoch 60, loss 0.60\n",
      "epoch 61, loss 0.59\n",
      "epoch 62, loss 0.59\n",
      "epoch 63, loss 0.57\n",
      "epoch 64, loss 0.57\n",
      "epoch 65, loss 0.57\n",
      "epoch 66, loss 0.54\n",
      "epoch 67, loss 0.55\n",
      "epoch 68, loss 0.52\n",
      "epoch 69, loss 0.52\n",
      "epoch 70, loss 0.52\n",
      "epoch 71, loss 0.50\n",
      "epoch 72, loss 0.50\n",
      "epoch 73, loss 0.50\n",
      "epoch 74, loss 0.48\n",
      "epoch 75, loss 0.47\n",
      "epoch 76, loss 0.47\n",
      "epoch 77, loss 0.46\n",
      "epoch 78, loss 0.45\n",
      "epoch 79, loss 0.45\n",
      "epoch 80, loss 0.44\n",
      "epoch 81, loss 0.43\n",
      "epoch 82, loss 0.42\n",
      "epoch 83, loss 0.42\n",
      "epoch 84, loss 0.40\n",
      "epoch 85, loss 0.41\n",
      "epoch 86, loss 0.39\n",
      "epoch 87, loss 0.39\n",
      "epoch 88, loss 0.37\n",
      "epoch 89, loss 0.37\n",
      "epoch 90, loss 0.36\n",
      "epoch 91, loss 0.35\n",
      "epoch 92, loss 0.35\n",
      "epoch 93, loss 0.35\n",
      "epoch 94, loss 0.33\n",
      "epoch 95, loss 0.33\n",
      "epoch 96, loss 0.33\n",
      "epoch 97, loss 0.31\n",
      "epoch 98, loss 0.31\n",
      "epoch 99, loss 0.31\n",
      "epoch 100, loss 0.31\n",
      "epoch 101, loss 0.30\n",
      "epoch 102, loss 0.29\n",
      "epoch 103, loss 0.29\n",
      "epoch 104, loss 0.29\n",
      "epoch 105, loss 0.28\n",
      "epoch 106, loss 0.28\n",
      "epoch 107, loss 0.28\n",
      "epoch 108, loss 0.27\n",
      "epoch 109, loss 0.26\n",
      "epoch 110, loss 0.26\n",
      "epoch 111, loss 0.26\n",
      "epoch 112, loss 0.27\n",
      "epoch 113, loss 0.25\n",
      "epoch 114, loss 0.25\n",
      "epoch 115, loss 0.25\n",
      "epoch 116, loss 0.24\n",
      "epoch 117, loss 0.24\n",
      "epoch 118, loss 0.23\n",
      "epoch 119, loss 0.24\n",
      "epoch 120, loss 0.24\n",
      "epoch 121, loss 0.24\n",
      "epoch 122, loss 0.23\n",
      "epoch 123, loss 0.23\n",
      "epoch 124, loss 0.23\n",
      "epoch 125, loss 0.22\n",
      "epoch 126, loss 0.22\n",
      "epoch 127, loss 0.22\n",
      "epoch 128, loss 0.22\n",
      "epoch 129, loss 0.21\n",
      "epoch 130, loss 0.22\n",
      "epoch 131, loss 0.21\n",
      "epoch 132, loss 0.21\n",
      "epoch 133, loss 0.21\n",
      "epoch 134, loss 0.21\n",
      "epoch 135, loss 0.21\n",
      "epoch 136, loss 0.20\n",
      "epoch 137, loss 0.20\n",
      "epoch 138, loss 0.19\n",
      "epoch 139, loss 0.20\n",
      "epoch 140, loss 0.19\n",
      "epoch 141, loss 0.20\n",
      "epoch 142, loss 0.19\n",
      "epoch 143, loss 0.19\n",
      "epoch 144, loss 0.19\n",
      "epoch 145, loss 0.19\n",
      "epoch 146, loss 0.18\n",
      "epoch 147, loss 0.19\n",
      "epoch 148, loss 0.19\n",
      "epoch 149, loss 0.18\n",
      "epoch 150, loss 0.18\n",
      "epoch 151, loss 0.18\n",
      "epoch 152, loss 0.18\n",
      "epoch 153, loss 0.18\n",
      "epoch 154, loss 0.18\n",
      "epoch 155, loss 0.18\n",
      "epoch 156, loss 0.19\n",
      "epoch 157, loss 0.18\n",
      "epoch 158, loss 0.17\n",
      "epoch 159, loss 0.18\n",
      "epoch 160, loss 0.18\n",
      "epoch 161, loss 0.17\n",
      "epoch 162, loss 0.17\n",
      "epoch 163, loss 0.17\n",
      "epoch 164, loss 0.17\n",
      "epoch 165, loss 0.17\n",
      "epoch 166, loss 0.17\n",
      "epoch 167, loss 0.17\n",
      "epoch 168, loss 0.16\n",
      "epoch 169, loss 0.17\n",
      "epoch 170, loss 0.18\n",
      "epoch 171, loss 0.16\n",
      "epoch 172, loss 0.16\n",
      "epoch 173, loss 0.17\n",
      "epoch 174, loss 0.16\n",
      "epoch 175, loss 0.17\n",
      "epoch 176, loss 0.16\n",
      "epoch 177, loss 0.16\n",
      "epoch 178, loss 0.16\n",
      "epoch 179, loss 0.16\n",
      "epoch 180, loss 0.16\n",
      "epoch 181, loss 0.15\n",
      "epoch 182, loss 0.16\n",
      "epoch 183, loss 0.15\n",
      "epoch 184, loss 0.15\n",
      "epoch 185, loss 0.15\n",
      "epoch 186, loss 0.15\n",
      "epoch 187, loss 0.15\n",
      "epoch 188, loss 0.15\n",
      "epoch 189, loss 0.15\n",
      "epoch 190, loss 0.15\n",
      "epoch 191, loss 0.15\n",
      "epoch 192, loss 0.15\n",
      "epoch 193, loss 0.16\n",
      "epoch 194, loss 0.15\n",
      "epoch 195, loss 0.14\n",
      "epoch 196, loss 0.14\n",
      "epoch 197, loss 0.14\n",
      "epoch 198, loss 0.14\n",
      "epoch 199, loss 0.14\n",
      "epoch 200, loss 0.14\n",
      "epoch 201, loss 0.14\n",
      "epoch 202, loss 0.14\n",
      "epoch 203, loss 0.14\n",
      "epoch 204, loss 0.14\n",
      "epoch 205, loss 0.14\n",
      "epoch 206, loss 0.14\n",
      "epoch 207, loss 0.13\n",
      "epoch 208, loss 0.14\n",
      "epoch 209, loss 0.14\n",
      "epoch 210, loss 0.14\n",
      "epoch 211, loss 0.14\n",
      "epoch 212, loss 0.14\n",
      "epoch 213, loss 0.13\n",
      "epoch 214, loss 0.13\n",
      "epoch 215, loss 0.13\n",
      "epoch 216, loss 0.14\n",
      "epoch 217, loss 0.13\n",
      "epoch 218, loss 0.13\n",
      "epoch 219, loss 0.12\n",
      "epoch 220, loss 0.14\n",
      "epoch 221, loss 0.13\n",
      "epoch 222, loss 0.13\n",
      "epoch 223, loss 0.12\n",
      "epoch 224, loss 0.13\n",
      "epoch 225, loss 0.12\n",
      "epoch 226, loss 0.13\n",
      "epoch 227, loss 0.13\n",
      "epoch 228, loss 0.12\n",
      "epoch 229, loss 0.12\n",
      "epoch 230, loss 0.13\n",
      "epoch 231, loss 0.13\n",
      "epoch 232, loss 0.12\n",
      "epoch 233, loss 0.12\n",
      "epoch 234, loss 0.12\n",
      "epoch 235, loss 0.12\n",
      "epoch 236, loss 0.12\n",
      "epoch 237, loss 0.12\n",
      "epoch 238, loss 0.12\n",
      "epoch 239, loss 0.12\n",
      "epoch 240, loss 0.11\n",
      "epoch 241, loss 0.12\n",
      "epoch 242, loss 0.12\n",
      "epoch 243, loss 0.12\n",
      "epoch 244, loss 0.12\n",
      "epoch 245, loss 0.12\n",
      "epoch 246, loss 0.11\n",
      "epoch 247, loss 0.11\n",
      "epoch 248, loss 0.11\n",
      "epoch 249, loss 0.11\n",
      "epoch 250, loss 0.11\n",
      "epoch 251, loss 0.12\n",
      "epoch 252, loss 0.11\n",
      "epoch 253, loss 0.12\n",
      "epoch 254, loss 0.11\n",
      "epoch 255, loss 0.11\n",
      "epoch 256, loss 0.11\n",
      "epoch 257, loss 0.11\n",
      "epoch 258, loss 0.10\n",
      "epoch 259, loss 0.11\n",
      "epoch 260, loss 0.11\n",
      "epoch 261, loss 0.11\n",
      "epoch 262, loss 0.11\n",
      "epoch 263, loss 0.11\n",
      "epoch 264, loss 0.11\n",
      "epoch 265, loss 0.11\n",
      "epoch 266, loss 0.11\n",
      "epoch 267, loss 0.10\n",
      "epoch 268, loss 0.10\n",
      "epoch 269, loss 0.10\n",
      "epoch 270, loss 0.10\n",
      "epoch 271, loss 0.10\n",
      "epoch 272, loss 0.11\n",
      "epoch 273, loss 0.10\n",
      "epoch 274, loss 0.10\n",
      "epoch 275, loss 0.11\n",
      "epoch 276, loss 0.11\n",
      "epoch 277, loss 0.10\n",
      "epoch 278, loss 0.11\n",
      "epoch 279, loss 0.10\n",
      "epoch 280, loss 0.11\n",
      "epoch 281, loss 0.10\n",
      "epoch 282, loss 0.10\n",
      "epoch 283, loss 0.11\n",
      "epoch 284, loss 0.10\n",
      "epoch 285, loss 0.10\n",
      "epoch 286, loss 0.10\n",
      "epoch 287, loss 0.10\n",
      "epoch 288, loss 0.10\n",
      "epoch 289, loss 0.09\n",
      "epoch 290, loss 0.10\n",
      "epoch 291, loss 0.10\n",
      "epoch 292, loss 0.10\n",
      "epoch 293, loss 0.09\n",
      "epoch 294, loss 0.09\n",
      "epoch 295, loss 0.09\n",
      "epoch 296, loss 0.10\n",
      "epoch 297, loss 0.09\n",
      "epoch 298, loss 0.10\n",
      "epoch 299, loss 0.09\n",
      "epoch 300, loss 0.10\n"
     ]
    }
   ],
   "source": [
    "max_epoch = 300\n",
    "batch_size = 30\n",
    "hidden_size = 10\n",
    "lr = 1.0\n",
    "\n",
    "# データ読み込み\n",
    "train_set = dezero.datasets.Spiral(train=True)\n",
    "# 隠れ層: 10nodes, 出力層: 3nodes\n",
    "model = MLP((hidden_size, 3))\n",
    "optimizer = optimizers.SGD(lr).setup(model)\n",
    "\n",
    "# 以下の2行で1エポックあたりのステップ数を計算\n",
    "data_size = len(train_set)\n",
    "max_iter = math.ceil(data_size / batch_size)\n",
    "\n",
    "for epoch in range(max_epoch):\n",
    "    # Shuffle index for data,\n",
    "    # 300あるデータのうち、idを並び替えてシャフルするエポックのループのたびにシャフルされることに注意\n",
    "    #index = np.random.permutation(data_size)\n",
    "\n",
    "    # index のシャフルのオリジナルは上記だがコメントアウトしている2行のほうが高速で現在はこちらを使うべきだろう\n",
    "    rng = np.random.default_rng()\n",
    "    index = rng.permutation(data_size)\n",
    "    sum_loss = 0\n",
    "\n",
    "    # max_iterはデータサイズ/バッチサイズなので10となる。\n",
    "    for i in range(max_iter):\n",
    "        # Create minibatch, # シャフルされたデータから、バッチサイズ分データを切り取る\n",
    "        batch_start = i * batch_size\n",
    "        batch_end   = (i + 1) * batch_size\n",
    "        batch_index = index[batch_start:batch_end]\n",
    "        batch = [train_set[i] for i in batch_index]            # [変更点]\n",
    "        batch_x = np.array([example[0] for example in batch])  # [変更点]　data\n",
    "        batch_t = np.array([example[1] for example in batch])  # [変更点]　label\n",
    "\n",
    "        y = model(batch_x)\n",
    "        loss = F.softmax_cross_entropy(y, batch_t)\n",
    "        model.cleargrads()      # ループが回るので、いったんCleanUpが必要\n",
    "        loss.backward()\n",
    "        optimizer.update()\n",
    "\n",
    "        # loss.dataはスカラー値, バッチ処理数分の長さを書ける\n",
    "        # loss.dataは30データ分まとまった、平均値として出力される。\n",
    "        # 最後にdata_sizeで割って1データあたりのavg_lossを求めるので、\n",
    "        # いったんlen(batch_t) = 30 をかけている\n",
    "        sum_loss += float(loss.data) * len(batch_t)\n",
    "\n",
    "    # Print loss every epoch\n",
    "    avg_loss = sum_loss / data_size\n",
    "    print('epoch %d, loss %.2f' % (epoch + 1, avg_loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac96ed8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 49.5 データセットの前処理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb84130c",
   "metadata": {},
   "source": [
    "### 前処理の例\n",
    "\n",
    "- データからある値を差し引く\n",
    "- データの形状を変形する\n",
    "- データ拡張処理 (データを増やす)\n",
    "    - 画像を回転させる\n",
    "    - 画像を左右反転させる"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59c700bd",
   "metadata": {},
   "source": [
    "### `Dataset()` クラスの改善\n",
    "\n",
    "- 前処理およびデータ拡張を対応可能にするために、ユーザが定義した関数を関数オブジェクトで引数で渡せるようにする\n",
    "- コンストラクタの引数説明\n",
    "    - `transform`: 学習データ用の前処理関数オブジェクトが引数として渡される\n",
    "        - 指定されなかったとき(Default値)\n",
    "            - `self.transform = lambda x: x` が実行される\n",
    "            - これは値をそのまま渡すだけの関数(つまり何もしない)\n",
    "    - `target_transform`: ラベル用の前処理関数オブジェクトが引数として渡される \n",
    "        - 指定されなかったとき(Default値)\n",
    "            - `self.target_transform = lambda x: x` が実行\n",
    "            - これは値をそのまま渡すだけの関数(つまり何もしない)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "871e8031",
   "metadata": {},
   "source": [
    "```python\n",
    "class Dataset:\n",
    "    def __init__(self, train=True, transform=None, target_transform=None):   # 変更\n",
    "        self.train = train                           \n",
    "        self.transform = transform                  # 追記  \n",
    "        self.target_transform = target_transform    # 追記\n",
    "        if self.transform is None:                  # 追記: 引数に何も設定されなかったとき\n",
    "            self.transform = lambda x: x            # 追記: 前処理なしに値をそのまま返す関数を設定\n",
    "        if self.target_transform is None:           # 追記: 引数に何も設定されなかったとき\n",
    "            self.target_transform = lambda x: x     # 追記: 前処理なしに値をそのまま返す関数を設定\n",
    "\n",
    "        self.data = None\n",
    "        self.label = None\n",
    "        self.prepare()\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        assert np.isscalar(index)\n",
    "        if self.label is None:\n",
    "            return self.transform(self.data[index]), None   # 変更: 前処理関数を実行, 学習データのみ\n",
    "        else:\n",
    "            return self.transform(self.data[index]),\\\n",
    "                   self.target_transform(self.label[index]) # 変更: 前処理関数を実行, 学習データ, ラベルに対して実施\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def prepare(self):\n",
    "        pass\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd11173",
   "metadata": {},
   "source": [
    "### 使用例: 1/2にスケール変換する前処理\n",
    "\n",
    "- 1/2スケールを実現する関数`f`を定義し、その関数オブジェクトを `transform=f` として渡す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "924cda2c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.06990694 -0.00360829] 1\n",
      "[0.18524696 0.29104736] 1\n",
      "[ 0.06871315 -0.08589821] 2\n",
      "[0.1515844 0.03236  ] 0\n",
      "[-0.10424428  0.26525107] 1\n",
      "[-0.35371885 -0.066955  ] 2\n",
      "[ 0.24727833 -0.18695834] 0\n",
      "[0.11600986 0.06904139] 0\n",
      "[-0.07943024 -0.00953086] 1\n",
      "[ 0.00245854 -0.16998222] 2\n",
      "[-0.06497979 -0.00162078] 1\n",
      "[-0.11987292  0.12749699] 1\n",
      "[-0.16605952 -0.21289489] 2\n",
      "[-0.07203399  0.32716373] 1\n",
      "[-0.04386805  0.24104065] 1\n",
      "[-0.42339772  0.17981759] 2\n",
      "[0.17496437 0.30312946] 1\n",
      "[-0.13280705 -0.19990571] 2\n",
      "[ 0.01936758 -0.14370072] 2\n",
      "[-0.08994609  0.0031146 ] 1\n",
      "[-0.13261119 -0.22943251] 2\n",
      "[-0.00793436  0.2698834 ] 1\n",
      "[0.07531573 0.0934213 ] 0\n",
      "[-0.3890553   0.02712853] 2\n",
      "[-0.05284092 -0.01525901] 1\n",
      "[0.08585732 0.09084889] 0\n",
      "[-0.02530199 -0.213506  ] 2\n",
      "[-0.2939061  -0.11333232] 2\n",
      "[ 0.21367101 -0.05238989] 0\n",
      "[0.00999704 0.00024344] 2\n",
      "[-0.32779983 -0.32271856] 0\n",
      "[0.04666041 0.05871802] 0\n",
      "[-0.02338564 -0.00883808] 1\n",
      "[-0.29350457 -0.39859763] 0\n",
      "[0.09493664 0.05556109] 0\n",
      "[-0.13748518 -0.20278764] 2\n",
      "[-0.3313409  -0.09611554] 2\n",
      "[0.44809067 0.04140946] 1\n",
      "[-0.14283592  0.07209648] 1\n",
      "[-0.34781784 -0.11066952] 2\n",
      "[-0.36976123 -0.01329002] 2\n",
      "[0.32025346 0.30172458] 1\n",
      "[0.16982456 0.00772154] 0\n",
      "[-0.00320268 -0.3799865 ] 0\n",
      "[-0.14945818 -0.37641367] 0\n",
      "[-0.09677401  0.2196242 ] 1\n",
      "[ 0.21866679 -0.05300786] 0\n",
      "[0.4682776  0.04020055] 1\n",
      "[-0.20769617 -0.21647702] 2\n",
      "[-0.07572679  0.16879115] 1\n",
      "[0.06949082 0.07871484] 0\n",
      "[-0.10930643  0.17931008] 1\n",
      "[0.15677038 0.29038432] 1\n",
      "[-0.2987155   0.39470753] 2\n",
      "[0.10502522 0.07661399] 0\n",
      "[-0.3554548   0.17226982] 2\n",
      "[0.01126807 0.02780343] 0\n",
      "[-0.15412231 -0.40143034] 0\n",
      "[-0.04159261  0.2515851 ] 1\n",
      "[-0.3737443   0.22257626] 2\n",
      "[ 0.07788847 -0.12819277] 2\n",
      "[0.17367132 0.2747058 ] 1\n",
      "[-0.33176407 -0.12632337] 2\n",
      "[-0.02569661 -0.01548173] 1\n",
      "[-0.3396928  -0.35314134] 0\n",
      "[-0.00774833 -0.39492399] 0\n",
      "[0.22304097 0.30145934] 1\n",
      "[0.03132478 0.30338714] 1\n",
      "[-0.08518139 -0.37545857] 0\n",
      "[0.00712548 0.01868763] 0\n",
      "[-0.00285402  0.26498464] 1\n",
      "[-0.16062422  0.03774729] 1\n",
      "[ 0.06636874 -0.09997594] 2\n",
      "[0.2851737  0.28049234] 1\n",
      "[ 0.04845344 -0.12063277] 2\n",
      "[ 0.045827  -0.0832159] 2\n",
      "[-0.38754883  0.11760483] 2\n",
      "[0.3311475 0.1535133] 1\n",
      "[ 0.23106864 -0.18339108] 0\n",
      "[ 0.03717182 -0.01477348] 2\n",
      "[ 0.21780582 -0.22756456] 0\n",
      "[-0.09763245  0.19714944] 1\n",
      "[0.13595146 0.09349973] 0\n",
      "[-0.34169036 -0.3441986 ] 0\n",
      "[-0.13417971  0.19292694] 1\n",
      "[-0.09890374 -0.42874008] 0\n",
      "[-0.28379476 -0.1780043 ] 2\n",
      "[-0.30562612 -0.14897206] 2\n",
      "[-0.12250572  0.02484651] 1\n",
      "[-0.20100139 -0.1949319 ] 2\n",
      "[-0.04435918 -0.00756725] 1\n",
      "[0.04142118 0.05009278] 0\n",
      "[-0.19861037 -0.4259741 ] 0\n",
      "[0.07058036 0.09079324] 0\n",
      "[-0.00019302  0.01499876] 0\n",
      "[-0.09406789 -0.39906293] 0\n",
      "[0.00047096 0.02499556] 0\n",
      "[-0.11728672 -0.22078004] 2\n",
      "[ 0.02185456 -0.369354  ] 0\n",
      "[ 0.05174551 -0.37141272] 0\n",
      "[-0.05694119 -0.43125713] 0\n",
      "[ 0.21202031 -0.17513534] 0\n",
      "[-0.31513134  0.36206663] 2\n",
      "[0.13788784 0.28321713] 1\n",
      "[0.01016438 0.04383703] 0\n",
      "[-0.2459059  -0.18043084] 2\n",
      "[ 0.23764515 -0.03353779] 0\n",
      "[0.4225587 0.1032916] 1\n",
      "[0.03914881 0.06976654] 0\n",
      "[ 0.46681464 -0.14894329] 1\n",
      "[ 0.16411714 -0.27470997] 0\n",
      "[ 0.19338651 -0.17378624] 0\n",
      "[ 0.06712331 -0.10544886] 2\n",
      "[ 0.0812566  -0.34043702] 0\n",
      "[-0.40455508  0.06659725] 2\n",
      "[ 0.21221559 -0.16692677] 0\n",
      "[-0.01193078 -0.00909156] 1\n",
      "[ 0.06046144 -0.35488647] 0\n",
      "[-0.14320484 -0.39483207] 0\n",
      "[-0.36407685 -0.25587702] 0\n",
      "[-0.38141063  0.05244938] 2\n",
      "[-0.36592638  0.10245916] 2\n",
      "[-0.09126577  0.02637347] 1\n",
      "[0.43306008 0.10239121] 1\n",
      "[ 0.0905899  -0.35357952] 0\n",
      "[-0.05642973 -0.02038837] 1\n",
      "[ 0.18380672 -0.24339287] 0\n",
      "[0.06199728 0.05814927] 0\n",
      "[ 0.0403487  -0.01992441] 2\n",
      "[0.32340455 0.2520109 ] 1\n",
      "[0.00256334 0.00966588] 0\n",
      "[-0.05249438  0.22392932] 1\n",
      "[-0.04479603 -0.02221072] 1\n",
      "[0.36755282 0.20323615] 1\n",
      "[0.14988808 0.05597822] 0\n",
      "[ 0.04610008 -0.02999639] 2\n",
      "[-0.28785294  0.39034048] 2\n",
      "[-0.0374436   0.25728968] 1\n",
      "[0.06961796 0.06464008] 0\n",
      "[0.06617621 0.3130826 ] 1\n",
      "[0.45889214 0.15698095] 1\n",
      "[0.45436382 0.13848656] 1\n",
      "[-0.16723013 -0.1990831 ] 2\n",
      "[-0.07338936  0.21269463] 1\n",
      "[ 0.4754481  -0.06594771] 1\n",
      "[0.40733525 0.13776061] 1\n",
      "[-0.0848946  0.0042315] 1\n",
      "[0.41676277 0.18257545] 1\n",
      "[-0.28977183 -0.13576557] 2\n",
      "[ 0.1402564 -0.2423389] 0\n",
      "[ 0.01105973 -0.1345462 ] 2\n",
      "[-0.00919984 -0.00391957] 1\n",
      "[ 0.04071719 -0.02901914] 2\n",
      "[-0.40585697  0.2056821 ] 2\n",
      "[ 0.022497   -0.15841049] 2\n",
      "[0.18937476 0.01540139] 0\n",
      "[ 0.21337788 -0.02636062] 0\n",
      "[-0.3560587   0.21318349] 2\n",
      "[ 0.2504043  -0.08673339] 0\n",
      "[-0.11667746  0.05732689] 1\n",
      "[0.04030995 0.08046805] 0\n",
      "[ 0.15222092 -0.2927948 ] 0\n",
      "[-0.37041152 -0.29735553] 0\n",
      "[ 0.49449772 -0.02229358] 1\n",
      "[-0.32545388  0.31077287] 2\n",
      "[ 0.23482844 -0.09940123] 0\n",
      "[-0.03794078 -0.01266874] 1\n",
      "[-0.04017094 -0.22646478] 2\n",
      "[ 0.0048994  -0.00099792] 2\n",
      "[0.3090518 0.221104 ] 1\n",
      "[ 0.20954122 -0.01387356] 0\n",
      "[-0.14619392  0.03357583] 1\n",
      "[ 0.2273892  -0.03455649] 0\n",
      "[ 0.00973305 -0.17973666] 2\n",
      "[ 0.18494691 -0.00443163] 0\n",
      "[-0. -0.] 1\n",
      "[-0.00058328 -0.4149996 ] 0\n",
      "[0.3553531  0.21435758] 1\n",
      "[0.02992204 0.04005835] 0\n",
      "[ 0.05187653 -0.13003394] 2\n",
      "[-0.3923648   0.14983279] 2\n",
      "[-0.15238501 -0.2408398 ] 2\n",
      "[ 0.01634318 -0.1037203 ] 2\n",
      "[0.11560956 0.0789584 ] 0\n",
      "[-0.42193407  0.1414095 ] 2\n",
      "[0.07679982 0.06404519] 0\n",
      "[0.25277776 0.29699057] 1\n",
      "[-0.11197443  0.0262055 ] 1\n",
      "[ 0.19887824 -0.02115293] 0\n",
      "[-0.01921767 -0.33444834] 0\n",
      "[-0.06262084  0.20567846] 1\n",
      "[ 0.04686979 -0.03745962] 2\n",
      "[0.15910378 0.3340449 ] 1\n",
      "[0.02826138 0.28861964] 1\n",
      "[-0.1445732   0.13085714] 1\n",
      "[-0.0234059 -0.1935902] 2\n",
      "[-0.2932819 -0.1400383] 2\n",
      "[-0.37088072  0.05543001] 2\n",
      "[-0.07646701 -0.22221115] 2\n",
      "[-0.15363626  0.07277294] 1\n",
      "[0.06267779 0.29337943] 1\n",
      "[ 0.02529576 -0.15292196] 2\n",
      "[-0.1350862  0.0526946] 1\n",
      "[-0.3924399  0.077401 ] 2\n",
      "[-0.01358195 -0.01468096] 1\n",
      "[ 0.18399769 -0.29183874] 0\n",
      "[ 0.06895822 -0.38385513] 0\n",
      "[-0.4248312  -0.01197687] 2\n",
      "[-0.46117535  0.09064931] 2\n",
      "[ 0.00123019 -0.18999602] 2\n",
      "[-0.02008925 -0.3994952 ] 0\n",
      "[-0.10716396  0.02481706] 1\n",
      "[ 0.0531854  -0.05288018] 2\n",
      "[ 0.26531154 -0.10409026] 0\n",
      "[-0.12543873  0.04990112] 1\n",
      "[-0.01446793  0.294645  ] 1\n",
      "[0.15066761 0.270923  ] 1\n",
      "[-0.13353442  0.13516124] 1\n",
      "[-0.0041851  -0.00273586] 1\n",
      "[ 0. -0.] 2\n",
      "[-0.0504427  -0.17799026] 2\n",
      "[-0.1237929   0.16340232] 1\n",
      "[ 0.05507575 -0.07118049] 2\n",
      "[ 0.19466168 -0.01148185] 0\n",
      "[-0.00048849  0.00497608] 0\n",
      "[ 0.06873329 -0.04093574] 2\n",
      "[ 0.21633175 -0.26229864] 0\n",
      "[-0.21816087 -0.41064686] 0\n",
      "[ 0.13900706 -0.29377207] 0\n",
      "[ 0.0648547  -0.07611746] 2\n",
      "[0.00326424 0.03484745] 0\n",
      "[-0.03363928 -0.0096643 ] 1\n",
      "[-0.09792969 -0.44433632] 0\n",
      "[ 0.04803953 -0.04378589] 2\n",
      "[0.05492848 0.04339196] 0\n",
      "[-0.30016306 -0.13712087] 2\n",
      "[0.3370939 0.2588295] 1\n",
      "[0.30264956 0.26912495] 1\n",
      "[-0.07450128  0.264716  ] 1\n",
      "[-0.18930635 -0.17084527] 2\n",
      "[-0.06920229  0.18764606] 1\n",
      "[-0.06956023  0.24012783] 1\n",
      "[-0.07294232 -0.01744755] 1\n",
      "[-0.39156765 -0.27762344] 0\n",
      "[-0.26436782 -0.3641561 ] 0\n",
      "[-0.13864096  0.01945982] 1\n",
      "[0.18160626 0.31083623] 1\n",
      "[ 0.21679121 -0.09070046] 0\n",
      "[-0.11993167  0.00404915] 1\n",
      "[-0.3497174  0.0140619] 2\n",
      "[-0.04716791 -0.19435841] 2\n",
      "[-0.1369861   0.07252453] 1\n",
      "[ 0.05054114 -0.06834174] 2\n",
      "[0.12996411 0.07489545] 0\n",
      "[ 0.01308313 -0.00733702] 2\n",
      "[-0.08930536  0.05522276] 1\n",
      "[ 0.05163088 -0.04726788] 2\n",
      "[-0.22538055 -0.18249275] 2\n",
      "[-0.37130463  0.23607813] 2\n",
      "[-0.00874572 -0.16476806] 2\n",
      "[ 0.14446466 -0.20403422] 0\n",
      "[-0.3559238   0.24128456] 2\n",
      "[-0.  0.] 0\n",
      "[0.2513216  0.22899225] 1\n",
      "[ 0.1976406  -0.22569491] 0\n",
      "[-0.10632411 -0.19829318] 2\n",
      "[0.17097798 0.03730322] 0\n",
      "[-0.03509351 -0.35326114] 0\n",
      "[0.03095254 0.04546362] 0\n",
      "[0.1360786 0.3708202] 1\n",
      "[-0.02421818 -0.17331612] 2\n",
      "[0.24675058 0.25522372] 1\n",
      "[0.4614827  0.05708509] 1\n",
      "[-0.08121299 -0.20446137] 2\n",
      "[-0.00099218  0.27999824] 1\n",
      "[-0.01683346 -0.20430769] 2\n",
      "[-0.09839395  0.01785019] 1\n",
      "[ 0.19889538 -0.04965511] 0\n",
      "[0.45928767 0.02558986] 1\n",
      "[ 0.02479452 -0.00319869] 2\n",
      "[-0.27445495 -0.14413354] 2\n",
      "[-0.20627868 -0.18186286] 2\n",
      "[0.17807673 0.02624273] 0\n",
      "[ 0.02998858 -0.00082762] 2\n",
      "[-0.07270714 -0.4187346 ] 0\n",
      "[ 0.01922555 -0.00551163] 2\n",
      "[0.01614049 0.05778828] 0\n",
      "[0.30377695 0.23652601] 1\n",
      "[0.1258991 0.0719334] 0\n",
      "[-0.12405611  0.13042271] 1\n",
      "[ 0.07505347 -0.08713195] 2\n",
      "[ 0.03108487 -0.01608511] 2\n",
      "[-0.22820288  0.41659147] 2\n",
      "[ 0.20551945 -0.20460145] 0\n",
      "[-0.10303729  0.47904417] 2\n",
      "[-0.28337163 -0.08200923] 2\n",
      "[-0.41796452  0.2037907 ] 2\n",
      "[ 0.21807441 -0.11166267] 0\n",
      "[-0.09426499 -0.18765423] 2\n",
      "[0.01253248 0.03798601] 0\n"
     ]
    }
   ],
   "source": [
    "# 1/2を実現する関数\n",
    "def f(x):\n",
    "    y = x / 2.0\n",
    "    return y\n",
    "\n",
    "# 関数オブジェクトを渡す\n",
    "train_set = dezero.datasets.Spiral(transform=f)\n",
    "#train_set = dezero.datasets.Spiral()\n",
    "\n",
    "# 1/2になったことを確認する\n",
    "for val in train_set:\n",
    "    print(val[0], val[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea3ea05",
   "metadata": {},
   "source": [
    "### 良く行われる前処理を `dezero/transforms.py` に実装\n",
    "\n",
    "DeZeroではよく使われる前処理を`dezero/transforms.py`に用意している\n",
    "\n",
    "- データの正規化\n",
    "- 画像データに関する変換処理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69564ea3",
   "metadata": {},
   "source": [
    "### 正規化の例"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c548f2c2",
   "metadata": {},
   "source": [
    "ここでは正規化の例を調べてみる\n",
    "\n",
    "- `(x - mean)/std` の処理が行われる\n",
    "- 以下のコードがコールされる\n",
    "\n",
    "```python\n",
    "class Normalize:\n",
    "    \"\"\"Normalize a NumPy array with mean and standard deviation.\n",
    "\n",
    "    Args:\n",
    "        mean (float or sequence): mean for all values or sequence of means for\n",
    "         each channel.\n",
    "        std (float or sequence):\n",
    "    \"\"\"\n",
    "    def __init__(self, mean=0, std=1):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, array):\n",
    "        mean, std = self.mean, self.std\n",
    "\n",
    "        if not np.isscalar(mean):\n",
    "            mshape = [1] * array.ndim\n",
    "            mshape[0] = len(array) if len(self.mean) == 1 else len(self.mean)\n",
    "            mean = np.array(self.mean, dtype=array.dtype).reshape(*mshape)\n",
    "        if not np.isscalar(std):\n",
    "            rshape = [1] * array.ndim\n",
    "            rshape[0] = len(array) if len(self.std) == 1 else len(self.std)\n",
    "            std = np.array(self.std, dtype=array.dtype).reshape(*rshape)\n",
    "        return (array - mean) / std\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cfad7eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.13981389 -0.00721657] 1\n",
      "[0.37049392 0.5820947 ] 1\n",
      "[ 0.1374263  -0.17179643] 2\n",
      "[0.3031688 0.06472  ] 0\n",
      "[-0.20848857  0.53050214] 1\n",
      "[-0.7074377 -0.13391  ] 2\n",
      "[ 0.49455667 -0.3739167 ] 0\n",
      "[0.23201972 0.13808277] 0\n",
      "[-0.15886047 -0.01906173] 1\n",
      "[ 0.00491708 -0.33996445] 2\n",
      "[-0.12995958 -0.00324155] 1\n",
      "[-0.23974584  0.25499398] 1\n",
      "[-0.33211905 -0.42578977] 2\n",
      "[-0.14406797  0.65432745] 1\n",
      "[-0.08773611  0.4820813 ] 1\n",
      "[-0.84679544  0.35963517] 2\n",
      "[0.34992874 0.6062589 ] 1\n",
      "[-0.2656141  -0.39981142] 2\n",
      "[ 0.03873516 -0.28740144] 2\n",
      "[-0.17989218  0.00622921] 1\n",
      "[-0.26522237 -0.45886502] 2\n",
      "[-0.01586872  0.5397668 ] 1\n",
      "[0.15063146 0.1868426 ] 0\n",
      "[-0.7781106   0.05425706] 2\n",
      "[-0.10568184 -0.03051801] 1\n",
      "[0.17171463 0.18169777] 0\n",
      "[-0.05060399 -0.427012  ] 2\n",
      "[-0.5878122  -0.22666465] 2\n",
      "[ 0.42734203 -0.10477977] 0\n",
      "[0.01999407 0.00048688] 2\n",
      "[-0.65559965 -0.6454371 ] 0\n",
      "[0.09332082 0.11743604] 0\n",
      "[-0.04677129 -0.01767616] 1\n",
      "[-0.58700913 -0.79719526] 0\n",
      "[0.18987328 0.11112218] 0\n",
      "[-0.27497035 -0.40557528] 2\n",
      "[-0.6626818  -0.19223109] 2\n",
      "[0.89618134 0.08281892] 1\n",
      "[-0.28567183  0.14419296] 1\n",
      "[-0.6956357  -0.22133903] 2\n",
      "[-0.73952246 -0.02658003] 2\n",
      "[0.6405069  0.60344917] 1\n",
      "[0.3396491  0.01544307] 0\n",
      "[-0.00640535 -0.759973  ] 0\n",
      "[-0.29891637 -0.75282735] 0\n",
      "[-0.19354802  0.4392484 ] 1\n",
      "[ 0.43733358 -0.10601573] 0\n",
      "[0.9365552  0.08040111] 1\n",
      "[-0.41539234 -0.43295404] 2\n",
      "[-0.15145358  0.3375823 ] 1\n",
      "[0.13898164 0.15742968] 0\n",
      "[-0.21861286  0.35862017] 1\n",
      "[0.31354076 0.58076864] 1\n",
      "[-0.597431    0.78941506] 2\n",
      "[0.21005045 0.15322797] 0\n",
      "[-0.7109096   0.34453964] 2\n",
      "[0.02253613 0.05560686] 0\n",
      "[-0.30824462 -0.8028607 ] 0\n",
      "[-0.08318522  0.5031702 ] 1\n",
      "[-0.7474886   0.44515252] 2\n",
      "[ 0.15577695 -0.25638554] 2\n",
      "[0.34734264 0.5494116 ] 1\n",
      "[-0.66352814 -0.25264674] 2\n",
      "[-0.05139323 -0.03096346] 1\n",
      "[-0.6793856 -0.7062827] 0\n",
      "[-0.01549666 -0.78984797] 0\n",
      "[0.44608194 0.6029187 ] 1\n",
      "[0.06264956 0.6067743 ] 1\n",
      "[-0.17036279 -0.75091714] 0\n",
      "[0.01425096 0.03737526] 0\n",
      "[-0.00570804  0.5299693 ] 1\n",
      "[-0.32124844  0.07549458] 1\n",
      "[ 0.13273749 -0.19995189] 2\n",
      "[0.5703474 0.5609847] 1\n",
      "[ 0.09690688 -0.24126554] 2\n",
      "[ 0.091654  -0.1664318] 2\n",
      "[-0.77509767  0.23520966] 2\n",
      "[0.662295  0.3070266] 1\n",
      "[ 0.46213728 -0.36678216] 0\n",
      "[ 0.07434364 -0.02954696] 2\n",
      "[ 0.43561164 -0.45512912] 0\n",
      "[-0.1952649   0.39429888] 1\n",
      "[0.27190292 0.18699946] 0\n",
      "[-0.6833807 -0.6883972] 0\n",
      "[-0.26835942  0.3858539 ] 1\n",
      "[-0.19780748 -0.85748017] 0\n",
      "[-0.5675895 -0.3560086] 2\n",
      "[-0.61125225 -0.29794413] 2\n",
      "[-0.24501143  0.04969303] 1\n",
      "[-0.40200278 -0.3898638 ] 2\n",
      "[-0.08871835 -0.0151345 ] 1\n",
      "[0.08284235 0.10018555] 0\n",
      "[-0.39722073 -0.8519482 ] 0\n",
      "[0.14116073 0.18158647] 0\n",
      "[-0.00038604  0.02999752] 0\n",
      "[-0.18813577 -0.79812586] 0\n",
      "[0.00094191 0.04999113] 0\n",
      "[-0.23457344 -0.4415601 ] 2\n",
      "[ 0.04370912 -0.738708  ] 0\n",
      "[ 0.10349102 -0.74282545] 0\n",
      "[-0.11388239 -0.86251426] 0\n",
      "[ 0.42404062 -0.3502707 ] 0\n",
      "[-0.6302627   0.72413325] 2\n",
      "[0.27577567 0.56643426] 1\n",
      "[0.02032876 0.08767407] 0\n",
      "[-0.4918118 -0.3608617] 2\n",
      "[ 0.4752903  -0.06707557] 0\n",
      "[0.8451174 0.2065832] 1\n",
      "[0.07829762 0.13953309] 0\n",
      "[ 0.9336293  -0.29788658] 1\n",
      "[ 0.3282343  -0.54941994] 0\n",
      "[ 0.38677302 -0.34757248] 0\n",
      "[ 0.13424662 -0.21089771] 2\n",
      "[ 0.1625132  -0.68087405] 0\n",
      "[-0.80911016  0.1331945 ] 2\n",
      "[ 0.42443117 -0.33385354] 0\n",
      "[-0.02386156 -0.01818313] 1\n",
      "[ 0.12092289 -0.70977294] 0\n",
      "[-0.28640968 -0.78966415] 0\n",
      "[-0.7281537  -0.51175404] 0\n",
      "[-0.76282126  0.10489876] 2\n",
      "[-0.73185277  0.20491832] 2\n",
      "[-0.18253154  0.05274695] 1\n",
      "[0.86612016 0.20478243] 1\n",
      "[ 0.1811798  -0.70715904] 0\n",
      "[-0.11285946 -0.04077674] 1\n",
      "[ 0.36761343 -0.48678574] 0\n",
      "[0.12399456 0.11629853] 0\n",
      "[ 0.08069741 -0.03984881] 2\n",
      "[0.6468091 0.5040218] 1\n",
      "[0.00512668 0.01933176] 0\n",
      "[-0.10498876  0.44785863] 1\n",
      "[-0.08959205 -0.04442143] 1\n",
      "[0.73510563 0.4064723 ] 1\n",
      "[0.29977617 0.11195645] 0\n",
      "[ 0.09220015 -0.05999277] 2\n",
      "[-0.5757059   0.78068095] 2\n",
      "[-0.07488721  0.51457936] 1\n",
      "[0.13923591 0.12928016] 0\n",
      "[0.13235243 0.6261652 ] 1\n",
      "[0.9177843 0.3139619] 1\n",
      "[0.90872765 0.27697313] 1\n",
      "[-0.33446026 -0.3981662 ] 2\n",
      "[-0.14677872  0.42538926] 1\n",
      "[ 0.9508962  -0.13189542] 1\n",
      "[0.8146705  0.27552122] 1\n",
      "[-0.16978921  0.00846301] 1\n",
      "[0.83352554 0.3651509 ] 1\n",
      "[-0.57954365 -0.27153113] 2\n",
      "[ 0.2805128 -0.4846778] 0\n",
      "[ 0.02211946 -0.2690924 ] 2\n",
      "[-0.01839967 -0.00783914] 1\n",
      "[ 0.08143438 -0.05803829] 2\n",
      "[-0.81171393  0.4113642 ] 2\n",
      "[ 0.044994   -0.31682098] 2\n",
      "[0.37874952 0.03080279] 0\n",
      "[ 0.42675576 -0.05272124] 0\n",
      "[-0.7121174   0.42636698] 2\n",
      "[ 0.5008086  -0.17346679] 0\n",
      "[-0.23335491  0.11465377] 1\n",
      "[0.08061991 0.1609361 ] 0\n",
      "[ 0.30444184 -0.5855896 ] 0\n",
      "[-0.74082303 -0.59471107] 0\n",
      "[ 0.98899543 -0.04458715] 1\n",
      "[-0.65090775  0.62154573] 2\n",
      "[ 0.46965688 -0.19880246] 0\n",
      "[-0.07588156 -0.02533749] 1\n",
      "[-0.08034188 -0.45292956] 2\n",
      "[ 0.00979881 -0.00199584] 2\n",
      "[0.6181036 0.442208 ] 1\n",
      "[ 0.41908243 -0.02774712] 0\n",
      "[-0.29238784  0.06715166] 1\n",
      "[ 0.4547784  -0.06911298] 0\n",
      "[ 0.01946609 -0.35947332] 2\n",
      "[ 0.36989382 -0.00886326] 0\n",
      "[-0. -0.] 1\n",
      "[-0.00116657 -0.8299992 ] 0\n",
      "[0.7107062  0.42871517] 1\n",
      "[0.05984409 0.0801167 ] 0\n",
      "[ 0.10375305 -0.26006788] 2\n",
      "[-0.7847296   0.29966557] 2\n",
      "[-0.30477002 -0.4816796 ] 2\n",
      "[ 0.03268636 -0.2074406 ] 2\n",
      "[0.23121913 0.1579168 ] 0\n",
      "[-0.84386814  0.282819  ] 2\n",
      "[0.15359965 0.12809038] 0\n",
      "[0.5055555  0.59398115] 1\n",
      "[-0.22394885  0.05241101] 1\n",
      "[ 0.3977565  -0.04230585] 0\n",
      "[-0.03843534 -0.6688967 ] 0\n",
      "[-0.12524168  0.41135693] 1\n",
      "[ 0.09373958 -0.07491923] 2\n",
      "[0.31820756 0.6680898 ] 1\n",
      "[0.05652277 0.5772393 ] 1\n",
      "[-0.2891464   0.26171428] 1\n",
      "[-0.0468118 -0.3871804] 2\n",
      "[-0.5865638 -0.2800766] 2\n",
      "[-0.74176145  0.11086001] 2\n",
      "[-0.15293403 -0.4444223 ] 2\n",
      "[-0.30727252  0.14554588] 1\n",
      "[0.12535559 0.58675885] 1\n",
      "[ 0.05059152 -0.30584392] 2\n",
      "[-0.2701724  0.1053892] 1\n",
      "[-0.7848798  0.154802 ] 2\n",
      "[-0.0271639  -0.02936192] 1\n",
      "[ 0.36799538 -0.5836775 ] 0\n",
      "[ 0.13791645 -0.76771027] 0\n",
      "[-0.8496624  -0.02395374] 2\n",
      "[-0.9223507   0.18129861] 2\n",
      "[ 0.00246038 -0.37999204] 2\n",
      "[-0.0401785 -0.7989904] 0\n",
      "[-0.21432792  0.04963413] 1\n",
      "[ 0.10637081 -0.10576035] 2\n",
      "[ 0.5306231  -0.20818052] 0\n",
      "[-0.25087747  0.09980225] 1\n",
      "[-0.02893586  0.58929   ] 1\n",
      "[0.30133522 0.541846  ] 1\n",
      "[-0.26706883  0.27032247] 1\n",
      "[-0.00837021 -0.00547171] 1\n",
      "[ 0. -0.] 2\n",
      "[-0.1008854  -0.35598052] 2\n",
      "[-0.2475858   0.32680464] 1\n",
      "[ 0.11015151 -0.14236097] 2\n",
      "[ 0.38932335 -0.02296369] 0\n",
      "[-0.00097699  0.00995216] 0\n",
      "[ 0.13746658 -0.08187149] 2\n",
      "[ 0.4326635 -0.5245973] 0\n",
      "[-0.43632174 -0.8212937 ] 0\n",
      "[ 0.27801412 -0.58754414] 0\n",
      "[ 0.1297094  -0.15223493] 2\n",
      "[0.00652849 0.0696949 ] 0\n",
      "[-0.06727856 -0.0193286 ] 1\n",
      "[-0.19585939 -0.88867265] 0\n",
      "[ 0.09607905 -0.08757178] 2\n",
      "[0.10985696 0.08678392] 0\n",
      "[-0.6003261  -0.27424175] 2\n",
      "[0.6741878 0.517659 ] 1\n",
      "[0.6052991 0.5382499] 1\n",
      "[-0.14900257  0.529432  ] 1\n",
      "[-0.3786127  -0.34169054] 2\n",
      "[-0.13840458  0.37529212] 1\n",
      "[-0.13912046  0.48025566] 1\n",
      "[-0.14588465 -0.0348951 ] 1\n",
      "[-0.7831353 -0.5552469] 0\n",
      "[-0.52873564 -0.7283122 ] 0\n",
      "[-0.2772819   0.03891963] 1\n",
      "[0.36321253 0.62167245] 1\n",
      "[ 0.43358243 -0.18140091] 0\n",
      "[-0.23986334  0.00809829] 1\n",
      "[-0.6994348  0.0281238] 2\n",
      "[-0.09433582 -0.38871682] 2\n",
      "[-0.2739722   0.14504905] 1\n",
      "[ 0.10108227 -0.13668348] 2\n",
      "[0.25992823 0.1497909 ] 0\n",
      "[ 0.02616625 -0.01467403] 2\n",
      "[-0.17861071  0.11044552] 1\n",
      "[ 0.10326176 -0.09453575] 2\n",
      "[-0.4507611 -0.3649855] 2\n",
      "[-0.74260926  0.47215626] 2\n",
      "[-0.01749143 -0.3295361 ] 2\n",
      "[ 0.2889293  -0.40806845] 0\n",
      "[-0.7118476   0.48256913] 2\n",
      "[-0.  0.] 0\n",
      "[0.5026432 0.4579845] 1\n",
      "[ 0.3952812  -0.45138982] 0\n",
      "[-0.21264821 -0.39658636] 2\n",
      "[0.34195596 0.07460645] 0\n",
      "[-0.07018702 -0.7065223 ] 0\n",
      "[0.06190507 0.09092724] 0\n",
      "[0.2721572 0.7416404] 1\n",
      "[-0.04843636 -0.34663224] 2\n",
      "[0.49350116 0.51044744] 1\n",
      "[0.9229654  0.11417017] 1\n",
      "[-0.16242598 -0.40892273] 2\n",
      "[-0.00198436  0.5599965 ] 1\n",
      "[-0.03366692 -0.40861538] 2\n",
      "[-0.19678791  0.03570037] 1\n",
      "[ 0.39779076 -0.09931022] 0\n",
      "[0.91857535 0.05117972] 1\n",
      "[ 0.04958905 -0.00639738] 2\n",
      "[-0.5489099  -0.28826708] 2\n",
      "[-0.41255736 -0.36372572] 2\n",
      "[0.35615346 0.05248545] 0\n",
      "[ 0.05997716 -0.00165524] 2\n",
      "[-0.14541428 -0.8374692 ] 0\n",
      "[ 0.03845111 -0.01102326] 2\n",
      "[0.03228098 0.11557655] 0\n",
      "[0.6075539  0.47305202] 1\n",
      "[0.2517982  0.14386679] 0\n",
      "[-0.24811222  0.26084542] 1\n",
      "[ 0.15010694 -0.17426391] 2\n",
      "[ 0.06216975 -0.03217021] 2\n",
      "[-0.45640576  0.83318293] 2\n",
      "[ 0.4110389 -0.4092029] 0\n",
      "[-0.20607458  0.95808834] 2\n",
      "[-0.56674325 -0.16401847] 2\n",
      "[-0.83592904  0.4075814 ] 2\n",
      "[ 0.43614882 -0.22332534] 0\n",
      "[-0.18852998 -0.37530845] 2\n",
      "[0.02506495 0.07597202] 0\n"
     ]
    }
   ],
   "source": [
    "from dezero import transforms\n",
    "\n",
    "f = transforms.Normalize(mean=0.0, std=1.0)\n",
    "train_set = dezero.datasets.Spiral(transform=f)\n",
    "for val in train_set:\n",
    "    print(val[0], val[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb6b1be",
   "metadata": {},
   "source": [
    "### 複数の変換処理を続けて行う場合\n",
    "\n",
    "- `Compose` クラスを利用する\n",
    "    - 与えられた処理を先頭から順に処理する\n",
    "- この例では、正規化を行い、float64に変換する処理を行う "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a7e2115",
   "metadata": {},
   "source": [
    "```python\n",
    "class Compose:\n",
    "    \"\"\"Compose several transforms.\n",
    "\n",
    "    Args:\n",
    "        transforms (list): list of transforms\n",
    "    \"\"\"\n",
    "    def __init__(self, transforms=[]):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    # Datasetクラスから, 実際のdata, ここでは(x ,y)座標のデータが引数に入る\n",
    "    def __call__(self, img):\n",
    "        if not self.transforms:    # リストが空のとき\n",
    "            return img\n",
    "        # 関数の引数にdataを引数に与えて、imgという変数を更新している\n",
    "        for t in self.transforms:\n",
    "            img = t(img)\n",
    "        return img\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bd99ceee",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = transforms.Compose([transforms.Normalize(mean=0.0, std=2.0), \n",
    "                        transforms.AsType(np.float64)])\n",
    "train_set = dezero.datasets.Spiral(transform=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "caf34325-8c93-4eab-8102-29d53240b2b2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.06990694 -0.00360829] 1\n",
      "[0.18524696 0.29104736] 1\n",
      "[ 0.06871315 -0.08589821] 2\n",
      "[0.1515844 0.03236  ] 0\n",
      "[-0.10424428  0.26525107] 1\n",
      "[-0.35371885 -0.066955  ] 2\n",
      "[ 0.24727833 -0.18695834] 0\n",
      "[0.11600986 0.06904139] 0\n",
      "[-0.07943024 -0.00953086] 1\n",
      "[ 0.00245854 -0.16998222] 2\n",
      "[-0.06497979 -0.00162078] 1\n",
      "[-0.11987292  0.12749699] 1\n",
      "[-0.16605952 -0.21289489] 2\n",
      "[-0.07203399  0.32716373] 1\n",
      "[-0.04386805  0.24104065] 1\n",
      "[-0.42339772  0.17981759] 2\n",
      "[0.17496437 0.30312946] 1\n",
      "[-0.13280705 -0.19990571] 2\n",
      "[ 0.01936758 -0.14370072] 2\n",
      "[-0.08994609  0.0031146 ] 1\n",
      "[-0.13261119 -0.22943251] 2\n",
      "[-0.00793436  0.26988339] 1\n",
      "[0.07531573 0.0934213 ] 0\n",
      "[-0.38905531  0.02712853] 2\n",
      "[-0.05284092 -0.01525901] 1\n",
      "[0.08585732 0.09084889] 0\n",
      "[-0.02530199 -0.213506  ] 2\n",
      "[-0.29390609 -0.11333232] 2\n",
      "[ 0.21367101 -0.05238989] 0\n",
      "[0.00999704 0.00024344] 2\n",
      "[-0.32779983 -0.32271856] 0\n",
      "[0.04666041 0.05871802] 0\n",
      "[-0.02338564 -0.00883808] 1\n",
      "[-0.29350457 -0.39859763] 0\n",
      "[0.09493664 0.05556109] 0\n",
      "[-0.13748518 -0.20278764] 2\n",
      "[-0.33134091 -0.09611554] 2\n",
      "[0.44809067 0.04140946] 1\n",
      "[-0.14283592  0.07209648] 1\n",
      "[-0.34781784 -0.11066952] 2\n",
      "[-0.36976123 -0.01329002] 2\n",
      "[0.32025346 0.30172458] 1\n",
      "[0.16982456 0.00772154] 0\n",
      "[-0.00320268 -0.37998649] 0\n",
      "[-0.14945818 -0.37641367] 0\n",
      "[-0.09677401  0.21962421] 1\n",
      "[ 0.21866679 -0.05300786] 0\n",
      "[0.4682776  0.04020055] 1\n",
      "[-0.20769617 -0.21647702] 2\n",
      "[-0.07572679  0.16879115] 1\n",
      "[0.06949082 0.07871484] 0\n",
      "[-0.10930643  0.17931008] 1\n",
      "[0.15677038 0.29038432] 1\n",
      "[-0.2987155   0.39470753] 2\n",
      "[0.10502522 0.07661399] 0\n",
      "[-0.3554548   0.17226982] 2\n",
      "[0.01126807 0.02780343] 0\n",
      "[-0.15412231 -0.40143034] 0\n",
      "[-0.04159261  0.2515851 ] 1\n",
      "[-0.37374431  0.22257626] 2\n",
      "[ 0.07788847 -0.12819277] 2\n",
      "[0.17367132 0.2747058 ] 1\n",
      "[-0.33176407 -0.12632337] 2\n",
      "[-0.02569661 -0.01548173] 1\n",
      "[-0.3396928  -0.35314134] 0\n",
      "[-0.00774833 -0.39492399] 0\n",
      "[0.22304097 0.30145934] 1\n",
      "[0.03132478 0.30338714] 1\n",
      "[-0.08518139 -0.37545857] 0\n",
      "[0.00712548 0.01868763] 0\n",
      "[-0.00285402  0.26498464] 1\n",
      "[-0.16062422  0.03774729] 1\n",
      "[ 0.06636874 -0.09997594] 2\n",
      "[0.28517371 0.28049234] 1\n",
      "[ 0.04845344 -0.12063277] 2\n",
      "[ 0.045827  -0.0832159] 2\n",
      "[-0.38754883  0.11760483] 2\n",
      "[0.33114749 0.1535133 ] 1\n",
      "[ 0.23106864 -0.18339108] 0\n",
      "[ 0.03717182 -0.01477348] 2\n",
      "[ 0.21780582 -0.22756456] 0\n",
      "[-0.09763245  0.19714944] 1\n",
      "[0.13595146 0.09349973] 0\n",
      "[-0.34169036 -0.34419861] 0\n",
      "[-0.13417971  0.19292694] 1\n",
      "[-0.09890374 -0.42874008] 0\n",
      "[-0.28379476 -0.17800429] 2\n",
      "[-0.30562612 -0.14897206] 2\n",
      "[-0.12250572  0.02484651] 1\n",
      "[-0.20100139 -0.19493189] 2\n",
      "[-0.04435918 -0.00756725] 1\n",
      "[0.04142118 0.05009278] 0\n",
      "[-0.19861037 -0.4259741 ] 0\n",
      "[0.07058036 0.09079324] 0\n",
      "[-0.00019302  0.01499876] 0\n",
      "[-0.09406789 -0.39906293] 0\n",
      "[0.00047096 0.02499556] 0\n",
      "[-0.11728672 -0.22078004] 2\n",
      "[ 0.02185456 -0.36935401] 0\n",
      "[ 0.05174551 -0.37141272] 0\n",
      "[-0.05694119 -0.43125713] 0\n",
      "[ 0.21202031 -0.17513534] 0\n",
      "[-0.31513134  0.36206663] 2\n",
      "[0.13788784 0.28321713] 1\n",
      "[0.01016438 0.04383703] 0\n",
      "[-0.24590591 -0.18043084] 2\n",
      "[ 0.23764515 -0.03353779] 0\n",
      "[0.4225587 0.1032916] 1\n",
      "[0.03914881 0.06976654] 0\n",
      "[ 0.46681464 -0.14894329] 1\n",
      "[ 0.16411714 -0.27470997] 0\n",
      "[ 0.19338651 -0.17378624] 0\n",
      "[ 0.06712331 -0.10544886] 2\n",
      "[ 0.0812566  -0.34043702] 0\n",
      "[-0.40455508  0.06659725] 2\n",
      "[ 0.21221559 -0.16692677] 0\n",
      "[-0.01193078 -0.00909156] 1\n",
      "[ 0.06046144 -0.35488647] 0\n",
      "[-0.14320484 -0.39483207] 0\n",
      "[-0.36407685 -0.25587702] 0\n",
      "[-0.38141063  0.05244938] 2\n",
      "[-0.36592638  0.10245916] 2\n",
      "[-0.09126577  0.02637347] 1\n",
      "[0.43306008 0.10239121] 1\n",
      "[ 0.0905899  -0.35357952] 0\n",
      "[-0.05642973 -0.02038837] 1\n",
      "[ 0.18380672 -0.24339287] 0\n",
      "[0.06199728 0.05814927] 0\n",
      "[ 0.0403487  -0.01992441] 2\n",
      "[0.32340455 0.25201091] 1\n",
      "[0.00256334 0.00966588] 0\n",
      "[-0.05249438  0.22392932] 1\n",
      "[-0.04479603 -0.02221072] 1\n",
      "[0.36755282 0.20323615] 1\n",
      "[0.14988808 0.05597822] 0\n",
      "[ 0.04610008 -0.02999639] 2\n",
      "[-0.28785294  0.39034048] 2\n",
      "[-0.0374436   0.25728968] 1\n",
      "[0.06961796 0.06464008] 0\n",
      "[0.06617621 0.31308261] 1\n",
      "[0.45889214 0.15698095] 1\n",
      "[0.45436382 0.13848656] 1\n",
      "[-0.16723013 -0.1990831 ] 2\n",
      "[-0.07338936  0.21269463] 1\n",
      "[ 0.4754481  -0.06594771] 1\n",
      "[0.40733525 0.13776061] 1\n",
      "[-0.0848946  0.0042315] 1\n",
      "[0.41676277 0.18257545] 1\n",
      "[-0.28977183 -0.13576557] 2\n",
      "[ 0.1402564 -0.2423389] 0\n",
      "[ 0.01105973 -0.13454621] 2\n",
      "[-0.00919984 -0.00391957] 1\n",
      "[ 0.04071719 -0.02901914] 2\n",
      "[-0.40585697  0.2056821 ] 2\n",
      "[ 0.022497   -0.15841049] 2\n",
      "[0.18937476 0.01540139] 0\n",
      "[ 0.21337788 -0.02636062] 0\n",
      "[-0.35605869  0.21318349] 2\n",
      "[ 0.2504043  -0.08673339] 0\n",
      "[-0.11667746  0.05732689] 1\n",
      "[0.04030995 0.08046805] 0\n",
      "[ 0.15222092 -0.29279479] 0\n",
      "[-0.37041152 -0.29735553] 0\n",
      "[ 0.49449772 -0.02229358] 1\n",
      "[-0.32545388  0.31077287] 2\n",
      "[ 0.23482844 -0.09940123] 0\n",
      "[-0.03794078 -0.01266874] 1\n",
      "[-0.04017094 -0.22646478] 2\n",
      "[ 0.0048994  -0.00099792] 2\n",
      "[0.30905181 0.221104  ] 1\n",
      "[ 0.20954122 -0.01387356] 0\n",
      "[-0.14619392  0.03357583] 1\n",
      "[ 0.2273892  -0.03455649] 0\n",
      "[ 0.00973305 -0.17973666] 2\n",
      "[ 0.18494691 -0.00443163] 0\n",
      "[-0. -0.] 1\n",
      "[-0.00058328 -0.4149996 ] 0\n",
      "[0.35535309 0.21435758] 1\n",
      "[0.02992204 0.04005835] 0\n",
      "[ 0.05187653 -0.13003394] 2\n",
      "[-0.3923648   0.14983279] 2\n",
      "[-0.15238501 -0.24083979] 2\n",
      "[ 0.01634318 -0.1037203 ] 2\n",
      "[0.11560956 0.0789584 ] 0\n",
      "[-0.42193407  0.1414095 ] 2\n",
      "[0.07679982 0.06404519] 0\n",
      "[0.25277776 0.29699057] 1\n",
      "[-0.11197443  0.0262055 ] 1\n",
      "[ 0.19887824 -0.02115293] 0\n",
      "[-0.01921767 -0.33444834] 0\n",
      "[-0.06262084  0.20567846] 1\n",
      "[ 0.04686979 -0.03745962] 2\n",
      "[0.15910378 0.3340449 ] 1\n",
      "[0.02826138 0.28861964] 1\n",
      "[-0.1445732   0.13085714] 1\n",
      "[-0.0234059  -0.19359019] 2\n",
      "[-0.29328191 -0.1400383 ] 2\n",
      "[-0.37088072  0.05543001] 2\n",
      "[-0.07646701 -0.22221115] 2\n",
      "[-0.15363626  0.07277294] 1\n",
      "[0.06267779 0.29337943] 1\n",
      "[ 0.02529576 -0.15292196] 2\n",
      "[-0.13508619  0.0526946 ] 1\n",
      "[-0.3924399  0.077401 ] 2\n",
      "[-0.01358195 -0.01468096] 1\n",
      "[ 0.18399769 -0.29183874] 0\n",
      "[ 0.06895822 -0.38385513] 0\n",
      "[-0.42483121 -0.01197687] 2\n",
      "[-0.46117535  0.09064931] 2\n",
      "[ 0.00123019 -0.18999602] 2\n",
      "[-0.02008925 -0.39949521] 0\n",
      "[-0.10716396  0.02481706] 1\n",
      "[ 0.0531854  -0.05288018] 2\n",
      "[ 0.26531154 -0.10409026] 0\n",
      "[-0.12543873  0.04990112] 1\n",
      "[-0.01446793  0.29464501] 1\n",
      "[0.15066761 0.27092299] 1\n",
      "[-0.13353442  0.13516124] 1\n",
      "[-0.0041851  -0.00273586] 1\n",
      "[ 0. -0.] 2\n",
      "[-0.0504427  -0.17799026] 2\n",
      "[-0.1237929   0.16340232] 1\n",
      "[ 0.05507575 -0.07118049] 2\n",
      "[ 0.19466168 -0.01148185] 0\n",
      "[-0.00048849  0.00497608] 0\n",
      "[ 0.06873329 -0.04093574] 2\n",
      "[ 0.21633175 -0.26229864] 0\n",
      "[-0.21816087 -0.41064686] 0\n",
      "[ 0.13900706 -0.29377207] 0\n",
      "[ 0.0648547  -0.07611746] 2\n",
      "[0.00326424 0.03484745] 0\n",
      "[-0.03363928 -0.0096643 ] 1\n",
      "[-0.09792969 -0.44433632] 0\n",
      "[ 0.04803953 -0.04378589] 2\n",
      "[0.05492848 0.04339196] 0\n",
      "[-0.30016306 -0.13712087] 2\n",
      "[0.33709389 0.2588295 ] 1\n",
      "[0.30264956 0.26912495] 1\n",
      "[-0.07450128  0.264716  ] 1\n",
      "[-0.18930635 -0.17084527] 2\n",
      "[-0.06920229  0.18764606] 1\n",
      "[-0.06956023  0.24012783] 1\n",
      "[-0.07294232 -0.01744755] 1\n",
      "[-0.39156765 -0.27762344] 0\n",
      "[-0.26436782 -0.3641561 ] 0\n",
      "[-0.13864096  0.01945982] 1\n",
      "[0.18160626 0.31083623] 1\n",
      "[ 0.21679121 -0.09070046] 0\n",
      "[-0.11993167  0.00404915] 1\n",
      "[-0.34971741  0.0140619 ] 2\n",
      "[-0.04716791 -0.19435841] 2\n",
      "[-0.13698611  0.07252453] 1\n",
      "[ 0.05054114 -0.06834174] 2\n",
      "[0.12996411 0.07489545] 0\n",
      "[ 0.01308313 -0.00733702] 2\n",
      "[-0.08930536  0.05522276] 1\n",
      "[ 0.05163088 -0.04726788] 2\n",
      "[-0.22538055 -0.18249275] 2\n",
      "[-0.37130463  0.23607813] 2\n",
      "[-0.00874572 -0.16476806] 2\n",
      "[ 0.14446466 -0.20403422] 0\n",
      "[-0.3559238   0.24128456] 2\n",
      "[-0.  0.] 0\n",
      "[0.25132161 0.22899225] 1\n",
      "[ 0.1976406  -0.22569491] 0\n",
      "[-0.10632411 -0.19829318] 2\n",
      "[0.17097798 0.03730322] 0\n",
      "[-0.03509351 -0.35326114] 0\n",
      "[0.03095254 0.04546362] 0\n",
      "[0.1360786  0.37082019] 1\n",
      "[-0.02421818 -0.17331612] 2\n",
      "[0.24675058 0.25522372] 1\n",
      "[0.4614827  0.05708509] 1\n",
      "[-0.08121299 -0.20446137] 2\n",
      "[-0.00099218  0.27999824] 1\n",
      "[-0.01683346 -0.20430769] 2\n",
      "[-0.09839395  0.01785019] 1\n",
      "[ 0.19889538 -0.04965511] 0\n",
      "[0.45928767 0.02558986] 1\n",
      "[ 0.02479452 -0.00319869] 2\n",
      "[-0.27445495 -0.14413354] 2\n",
      "[-0.20627868 -0.18186286] 2\n",
      "[0.17807673 0.02624273] 0\n",
      "[ 0.02998858 -0.00082762] 2\n",
      "[-0.07270714 -0.41873461] 0\n",
      "[ 0.01922555 -0.00551163] 2\n",
      "[0.01614049 0.05778828] 0\n",
      "[0.30377695 0.23652601] 1\n",
      "[0.12589911 0.0719334 ] 0\n",
      "[-0.12405611  0.13042271] 1\n",
      "[ 0.07505347 -0.08713195] 2\n",
      "[ 0.03108487 -0.01608511] 2\n",
      "[-0.22820288  0.41659147] 2\n",
      "[ 0.20551945 -0.20460145] 0\n",
      "[-0.10303729  0.47904417] 2\n",
      "[-0.28337163 -0.08200923] 2\n",
      "[-0.41796452  0.20379069] 2\n",
      "[ 0.21807441 -0.11166267] 0\n",
      "[-0.09426499 -0.18765423] 2\n",
      "[0.01253248 0.03798601] 0\n"
     ]
    }
   ],
   "source": [
    "for val in train_set:\n",
    "    print(val[0], val[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0ddbb5",
   "metadata": {},
   "source": [
    "## 補足"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "372daeea",
   "metadata": {},
   "source": [
    "### Softmax関数の復習\n",
    "\n",
    "$$\n",
    "p_k = \\frac{\\exp\\left(y_k\\right)}{\\sum_{i=1}^n \\exp\\left(y_i\\right)}\n",
    "$$\n",
    "\n",
    "このとき, \n",
    "$$\n",
    "p_1 + p_2 + \\cdot \\cdot \\cdot + p_n = 1\n",
    "$$\n",
    "\n",
    "- Softmax関数は定義式からわかるように指数関数の計算を行うため値が発散しがちになる\n",
    "- そのため、Softmax関数ではオーバーフロー対策を行うのが一般的(本書では説明しない)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('kinocode')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "c222fa9c04e7ed09ba82d4b2c90d6d09380978bc4549bc0b0460fb9c58f648a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
